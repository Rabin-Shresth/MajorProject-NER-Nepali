{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-multilingual-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.id2label = {0: \"location\", 1: \"people name\"}\n",
    "text = \"My name is Aman. I am a student.\"\n",
    "inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "predicted_labels_indices = torch.argmax(outputs.logits, dim=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 12 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Convert token IDs to labels\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m label_names \u001b[39m=\u001b[39m [model\u001b[39m.\u001b[39;49mconfig\u001b[39m.\u001b[39;49mid2label[label_id\u001b[39m.\u001b[39;49mitem()] \u001b[39mfor\u001b[39;49;00m label_id \u001b[39min\u001b[39;49;00m predicted_labels_indices]\n\u001b[0;32m      4\u001b[0m \u001b[39m# Print token and corresponding label name\u001b[39;00m\n\u001b[0;32m      5\u001b[0m decoded_tokens \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mconvert_ids_to_tokens(inputs[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Convert token IDs to labels\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m label_names \u001b[39m=\u001b[39m [model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mid2label[label_id\u001b[39m.\u001b[39;49mitem()] \u001b[39mfor\u001b[39;00m label_id \u001b[39min\u001b[39;00m predicted_labels_indices]\n\u001b[0;32m      4\u001b[0m \u001b[39m# Print token and corresponding label name\u001b[39;00m\n\u001b[0;32m      5\u001b[0m decoded_tokens \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39mconvert_ids_to_tokens(inputs[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mRuntimeError\u001b[0m: a Tensor with 12 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "# Convert token IDs to labels\n",
    "label_names = [model.config.id2label[label_id.item()] for label_id in predicted_labels_indices]\n",
    "\n",
    "# Print token and corresponding label name\n",
    "decoded_tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "for token, label_name in zip(decoded_tokens, label_names):\n",
    "    if '##' in token:\n",
    "        # Handle subword tokens by appending them to the previous token\n",
    "        print(f\"Token: {decoded_tokens[-1]}{token.replace('##', '')}\\tPredicted Label: {label_name}\")\n",
    "    else:\n",
    "        print(f\"Token: {token}\\tPredicted Label: {label_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: [CLS]\tPredicted Label: people name\n",
      "Token: मेरो\tPredicted Label: people name\n",
      "Token: नाम\tPredicted Label: people name\n",
      "Token: अमन\tPredicted Label: people name\n",
      "Token: हो\tPredicted Label: people name\n",
      "Token: ।\tPredicted Label: people name\n",
      "Token: म\tPredicted Label: people name\n",
      "Token: एक\tPredicted Label: people name\n",
      "Token: विद्यार्थी\tPredicted Label: people name\n",
      "Token: हूँ\tPredicted Label: people name\n",
      "Token: ।\tPredicted Label: people name\n",
      "Token: [SEP]\tPredicted Label: location\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertForTokenClassification.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "# Modify the id2label mapping in the model's configuration\n",
    "model.config.id2label = {0: \"location\", 1: \"people name\",2:\"organization\"}  # Modify this mapping according to your labels\n",
    "\n",
    "# Define an example input in Nepali\n",
    "text = \"मेरो नाम अमन हो। म एक विद्यार्थी हूँ।\"\n",
    "\n",
    "# Tokenize and encode input\n",
    "inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "\n",
    "# Run inference\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Get predicted labels (integer indices)\n",
    "predicted_label_indices = torch.argmax(outputs.logits, dim=2)[0]\n",
    "\n",
    "# Convert label indices to label names using modified model's configuration\n",
    "label_names = [model.config.id2label[label_id.item()] for label_id in predicted_label_indices]\n",
    "\n",
    "# Print token and corresponding label name\n",
    "decoded_tokens = []\n",
    "for token, label_name in zip(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0]), label_names):\n",
    "    if '##' in token and len(decoded_tokens) > 0:\n",
    "        decoded_tokens[-1] += token.replace('##', '')\n",
    "    else:\n",
    "        decoded_tokens.append(token.replace('##', ''))\n",
    "    \n",
    "for token, label_name in zip(decoded_tokens, label_names):\n",
    "    print(f\"Token: {token}\\tPredicted Label: {label_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
